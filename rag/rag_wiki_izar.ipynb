{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import jsonlines\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gpt_wrapper\n",
    "from gpt_wrapper.chat import Chat\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args={\"temperature\": 0.7, \"top_p\": 0.7, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_new_tokens\": 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Further the Wikipedia subset of 133K samples using GPTWrapper and GPT3.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_keywords = {\n",
    "    'computer science', \n",
    "    'computer software', \n",
    "    'computer systems', \n",
    "    'machine learning', \n",
    "    'artificial intelligence',\n",
    "    'mathematics',\n",
    "    'physics',\n",
    "    'cybersecurity',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading from the wikipedia_8_keywords.json file\n",
    "filtered_data_with_keywords = pd.read_json('data_wikipedia/wikipedia_8_keywords.json', orient='records', lines=True)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(filtered_data_with_keywords.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_prompt(document, keywords):\n",
    "    prompt = f'''You are a classifier. Determine if the following document is related to the given keywords based on it's Title and Content.\n",
    "    Keywords: {\", \".join(keywords)}\n",
    "    Document Title: {document['title']}\n",
    "    Document Content: {document['text']}\n",
    "    Answer with \"Yes\" or \"No\" only.'''\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_zero_shot(document, relevant_keywords, model_args):\n",
    "    instruction= \"You are a helpful educational AI bot. Your task is to determine if the following document is related to the given keywords. Answer ONLY with 'Yes' if the document is even remotely related to the keywords. Answer with 'No' if you are certain that the document is not related to the keywords at all.\"\n",
    "    with jsonlines.open(f\"data_wikipedia/wikipedia_8_keywords_gpt3.5.json\", mode=\"w\") as writer:\n",
    "        for example in tqdm(document):\n",
    "            # Limit the context length to the first 100 lines\n",
    "            limited_text = example[\"text\"].split('\\n')[:100]  # Split the text into lines and take the first 50\n",
    "            limited_example = example.copy()  # Create a copy of the example\n",
    "            limited_example[\"text\"] = '\\n'.join(limited_text)  # Join the limited text back into a single string\n",
    "            prompt = initial_prompt(limited_example, relevant_keywords)\n",
    "            chat_id = random.randrange(0, 2**16,)\n",
    "            chat = Chat.create(name=f\"{chat_id}\")\n",
    "            message = chat.ask(prompt, model_args=model_args, instruction=instruction)\n",
    "            preds = message.content.strip()\n",
    "            if preds:\n",
    "                pred = preds\n",
    "            else:\n",
    "                pred = \"none\"\n",
    "\n",
    "            print(\"Document Title:\", example[\"title\"])\n",
    "            print(\"Predicted answer:\", preds)\n",
    "\n",
    "            example[\"prediction\"] = preds  # Add the prediction to the example dictionary\n",
    "            writer.write(example)  # Write the example dictionary to the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the filtered dataset\n",
    "document_dataset = filtered_data_with_keywords.to_dict('records')\n",
    "predictions = generate_predictions_zero_shot(document_dataset, relevant_keywords, model_args)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
